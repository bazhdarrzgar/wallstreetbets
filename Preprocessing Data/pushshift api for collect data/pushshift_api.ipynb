{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ee2d297",
   "metadata": {},
   "source": [
    "# Collect r/wallstreetbets Data on Reddit in 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34447fe",
   "metadata": {},
   "source": [
    "## Install prawÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa882f8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: praw in /home/soyanswartz/.local/lib/python3.10/site-packages (7.6.0)\n",
      "Requirement already satisfied: prawcore<3,>=2.1 in /home/soyanswartz/.local/lib/python3.10/site-packages (from praw) (2.3.0)\n",
      "Requirement already satisfied: update-checker>=0.18 in /home/soyanswartz/.local/lib/python3.10/site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in /home/soyanswartz/.local/lib/python3.10/site-packages (from praw) (1.4.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in /home/soyanswartz/.local/lib/python3.10/site-packages (from prawcore<3,>=2.1->praw) (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/soyanswartz/.local/lib/python3.10/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/soyanswartz/.local/lib/python3.10/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/soyanswartz/.local/lib/python3.10/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/soyanswartz/.local/lib/python3.10/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install praw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a462db8d",
   "metadata": {},
   "source": [
    "## Packages I used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f177ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cac37245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import praw\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e2a8d3",
   "metadata": {},
   "source": [
    "## Environments setup for Reddit and neptune.ai secrets\n",
    "how you can use secrets api key with kaggle: [Feature Launch: User Secrets](https://www.kaggle.com/product-feedback/114053)\n",
    "\n",
    "### neptune.ai secret token\n",
    "\n",
    "* **What is neptune.ai**\n",
    "\n",
    "Neptune is metadata store that offers experiment tracking and model registry for machine learning researchers and engineers. With Neptune, you can log, query, manage, display, and compare all your model metadata in a single place.\n",
    "\n",
    "* Creating API token from neptune.ai\n",
    "\n",
    "1. step 1\n",
    "    - Sign Up form [neptune_api website](https://app.neptune.ai/) \n",
    "    \n",
    "    - Go to dashboard\n",
    "    \n",
    "    - in your profile menu select the ( GET your API token )\n",
    "    \n",
    "![image](images/get_api_token.png)\n",
    "\n",
    "2. step 2\n",
    "\n",
    "![image](images/1.png)\n",
    "\n",
    "\n",
    "### Reddit secret token\n",
    "\n",
    "1. step 1\n",
    "\n",
    "go to this [url](https://www.reddit.com/prefs/apps) and click to ( create new app... )\n",
    "\n",
    "![image](images/2.png)\n",
    "\n",
    "in the end you should get something like this\n",
    "\n",
    "![image](images/3.png)\n",
    "\n",
    "\n",
    "2. step 2\n",
    "\n",
    "after that you should get this data\n",
    "\n",
    "![image](images/4.png)\n",
    "\n",
    "    - below type of app you should get = REDDIT_PERSONAL_USE_SCRIPT_14_CHARS\n",
    "    - secret = REDDIT_SECRET_KEY_27_CHARS\n",
    "    - name = REDDIT_APP_NAME\n",
    "    - username of reddit profile = REDDIT_USER_NAME\n",
    "    - password reddit profile = REDDIT_LOGIN_PASSWORD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a602a2b",
   "metadata": {},
   "source": [
    "## Configure the api requirement for featching data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9de65b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_use_script = \"REDDIT_PERSONAL_USE_SCRIPT_14_CHARS\"\n",
    "client_secret = \"REDDIT_SECRET_KEY_27_CHARS\"\n",
    "user_agent = \"REDDIT_APP_NAME\"\n",
    "username = \"REDDIT_USER_NAME\"\n",
    "password = \"REDDIT_LOGIN_PASSWORD\"\n",
    "\n",
    "reddit = praw.Reddit(client_id=personal_use_script, \\\n",
    "                         client_secret=client_secret, \\\n",
    "                         user_agent=user_agent, \\\n",
    "                         username=username, \\\n",
    "                         password='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655ce705",
   "metadata": {},
   "source": [
    "## Build the dataset (daily update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b4b2d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(reddit, search_words='wallstreetbets', items_limit=4000):\n",
    "    \n",
    "    # Collect reddit posts\n",
    "    subreddit = reddit.subreddit(search_words)\n",
    "    new_subreddit = subreddit.new(limit=items_limit)\n",
    "    topics_dict = { \"title\":[],\n",
    "                \"score\":[],\n",
    "                \"id\":[], \"url\":[],\n",
    "                \"comms_num\": [],\n",
    "                \"created\": [],\n",
    "                \"body\":[]}\n",
    "    \n",
    "    print(f\"retreive new reddit posts ...\")\n",
    "    for submission in tqdm(new_subreddit):\n",
    "        topics_dict[\"title\"].append(submission.title)\n",
    "        topics_dict[\"score\"].append(submission.score)\n",
    "        topics_dict[\"id\"].append(submission.id)\n",
    "        topics_dict[\"url\"].append(submission.url)\n",
    "        topics_dict[\"comms_num\"].append(submission.num_comments)\n",
    "        topics_dict[\"created\"].append(submission.created)\n",
    "        topics_dict[\"body\"].append(submission.selftext)\n",
    "\n",
    "    for comment in tqdm(subreddit.comments(limit=items_limit)):\n",
    "        topics_dict[\"title\"].append(\"Comment\")\n",
    "        topics_dict[\"score\"].append(comment.score)\n",
    "        topics_dict[\"id\"].append(comment.id)\n",
    "        topics_dict[\"url\"].append(\"\")\n",
    "        topics_dict[\"comms_num\"].append(0)\n",
    "        topics_dict[\"created\"].append(comment.created)\n",
    "        topics_dict[\"body\"].append(comment.body)\n",
    "\n",
    "    topics_df = pd.DataFrame(topics_dict)\n",
    "    print(f\"new reddit posts retrieved: {len(topics_df)}\")\n",
    "    topics_df['timestamp'] = topics_df['created'].apply(lambda x: get_date(x))\n",
    "\n",
    "    return topics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661a44bc",
   "metadata": {},
   "source": [
    "## [Option] Update and save dataset\n",
    "We perform the following actions for meargin with old data from pass:\n",
    "\n",
    "* Load old data\n",
    "* Merge the two datasets\n",
    "* Save the merged data\n",
    "We also log here the information on the updated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1c82ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_and_save_dataset(topics_df):   \n",
    "    file_path = \"../input/wallstreetbets-2022/wallstreetbets_2022.csv\"\n",
    "    out_file_path = \"wallstreetbets_2022.csv\"\n",
    "    if run:\n",
    "        run[\"rows_new\"] = topics_df.shape[0]\n",
    "        run[\"cols_new\"] = topics_df.shape[1]\n",
    "    if os.path.exists(file_path):\n",
    "        topics_old_df = pd.read_csv(file_path)\n",
    "        if run:\n",
    "            run[\"rows_old\"] = topics_old_df.shape[0]\n",
    "            run[\"cols_old\"] = topics_old_df.shape[1]\n",
    "        print(f\"past reddit posts: {topics_old_df.shape}\")\n",
    "        topics_all_df = pd.concat([topics_old_df, topics_df], axis=0)\n",
    "        print(f\"new reddit posts: {topics_df.shape[0]} past posts: {topics_old_df.shape[0]} all posts: {topics_all_df.shape[0]}\")\n",
    "        topics_new_df = topics_all_df.drop_duplicates(subset = [\"id\"], keep='last', inplace=False)\n",
    "        print(f\"all reddit posts: {topics_new_df.shape}\")\n",
    "        if run:\n",
    "            run[\"rows_merged\"] = topics_old_df.shape[0]\n",
    "            run[\"cols_merged\"] = topics_old_df.shape[1]\n",
    "        topics_new_df.to_csv(out_file_path, index=False)\n",
    "    else:\n",
    "        print(f\"reddit posts: {topics_df.shape}\")\n",
    "        topics_df.to_csv(out_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dadbb3",
   "metadata": {},
   "source": [
    "## Run it all\n",
    "\n",
    "* Initialize connection\n",
    "* Build the dataset\n",
    "* Update and save the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84d16590",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = reddit_connection()\n",
    "topics_data_df = build_dataset(reddit)\n",
    "update_and_save_dataset(topics_data_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
