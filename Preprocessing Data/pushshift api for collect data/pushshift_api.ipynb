{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ee2d297",
   "metadata": {},
   "source": [
    "# Collect r/wallstreetbets Data on Reddit in 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34447fe",
   "metadata": {},
   "source": [
    "## Install prawÂ¶ for PushShift API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faa882f8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: praw in /home/soyanswartz/.local/lib/python3.10/site-packages (7.6.0)\n",
      "Requirement already satisfied: prawcore<3,>=2.1 in /home/soyanswartz/.local/lib/python3.10/site-packages (from praw) (2.3.0)\n",
      "Requirement already satisfied: update-checker>=0.18 in /home/soyanswartz/.local/lib/python3.10/site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in /home/soyanswartz/.local/lib/python3.10/site-packages (from praw) (1.4.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in /home/soyanswartz/.local/lib/python3.10/site-packages (from prawcore<3,>=2.1->praw) (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/soyanswartz/.local/lib/python3.10/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/soyanswartz/.local/lib/python3.10/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/soyanswartz/.local/lib/python3.10/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/soyanswartz/.local/lib/python3.10/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install praw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a462db8d",
   "metadata": {},
   "source": [
    "## Packages I used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f177ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cac37245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import praw\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e2a8d3",
   "metadata": {},
   "source": [
    "## Environments setup for Reddit\n",
    "\n",
    "### Reddit secret token\n",
    "\n",
    "1. step 1\n",
    "\n",
    "go to this [url](https://www.reddit.com/prefs/apps) and click to ( create new app... )\n",
    "\n",
    "![image](images/2.png)\n",
    "\n",
    "in the end you should get something like this\n",
    "\n",
    "![image](images/3.png)\n",
    "\n",
    "\n",
    "2. step 2\n",
    "\n",
    "after that you should get this data\n",
    "\n",
    "![image](images/4.png)\n",
    "\n",
    "    - below type of app you should get = REDDIT_PERSONAL_USE_SCRIPT_14_CHARS\n",
    "    - secret = REDDIT_SECRET_KEY_27_CHARS\n",
    "    - name = REDDIT_APP_NAME\n",
    "    - username of reddit profile = REDDIT_USER_NAME\n",
    "    - password reddit profile = REDDIT_LOGIN_PASSWORD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a602a2b",
   "metadata": {},
   "source": [
    "## Configure the api requirement for featching data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9de65b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date(created):\n",
    "    return dt.datetime.fromtimestamp(created)\n",
    "\n",
    "def reddit_connection():\n",
    "    personal_use_script = os.environ[\"REDDIT_PERSONAL_USE_SCRIPT_14_CHARS\"]\n",
    "    client_secret = os.environ[\"REDDIT_SECRET_KEY_27_CHARS\"]\n",
    "    user_agent = os.environ[\"REDDIT_APP_NAME\"]\n",
    "    username = os.environ[\"REDDIT_USER_NAME\"]\n",
    "    password = os.environ[\"REDDIT_LOGIN_PASSWORD\"]\n",
    "\n",
    "    reddit = praw.Reddit(client_id=personal_use_script, \\\n",
    "                         client_secret=client_secret, \\\n",
    "                         user_agent=user_agent, \\\n",
    "                         username=username, \\\n",
    "                         password='')\n",
    "    return reddit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655ce705",
   "metadata": {},
   "source": [
    "## Build the dataset (daily update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b4b2d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(reddit, search_words='wallstreetbets', items_limit=5000):\n",
    "\n",
    "subreddit = reddit.subreddit(search_words)\n",
    "    new_subreddit = subreddit.new(limit=items_limit)\n",
    "    topics_dict = { \"title\":[],\n",
    "                \"score\":[],\n",
    "                \"id\":[], \"url\":[],\n",
    "                \"comms_num\": [],\n",
    "                \"created\": [],\n",
    "                \"body\":[]}\n",
    "    \n",
    "    print(f\"featching data from wallstreet subreddit...\")\n",
    "    for submission in tqdm(new_subreddit):\n",
    "        topics_dict[\"title\"].append(submission.title)\n",
    "        topics_dict[\"score\"].append(submission.score)\n",
    "        topics_dict[\"id\"].append(submission.id)\n",
    "        topics_dict[\"url\"].append(submission.url)\n",
    "        topics_dict[\"comms_num\"].append(submission.num_comments)\n",
    "        topics_dict[\"created\"].append(submission.created)\n",
    "        topics_dict[\"body\"].append(submission.selftext)\n",
    "\n",
    "    for comment in tqdm(subreddit.comments(limit=2000)):\n",
    "        topics_dict[\"title\"].append(\"Comment\")\n",
    "        topics_dict[\"score\"].append(comment.score)\n",
    "        topics_dict[\"id\"].append(comment.id)\n",
    "        topics_dict[\"url\"].append(\"\")\n",
    "        topics_dict[\"comms_num\"].append(0)\n",
    "        topics_dict[\"created\"].append(comment.created)\n",
    "        topics_dict[\"body\"].append(comment.body)\n",
    "\n",
    "    topics_df = pd.DataFrame(topics_dict)\n",
    "    print(f\"featching data from wallstreet subreddit: {len(topics_df)}\")\n",
    "    topics_df['timestamp'] = topics_df['created'].apply(lambda x: get_date(x))\n",
    "\n",
    "    return topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff040382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_and_save_dataset(topics_df):   \n",
    "    file_path = \"Stock Market.csv\"\n",
    "    if os.path.exists(file_path):\n",
    "        topics_old_df = pd.read_csv(file_path)\n",
    "        print(f\"past reddit posts: {topics_old_df.shape}\")\n",
    "        topics_all_df = pd.concat([topics_old_df, topics_df], axis=0)\n",
    "        print(f\"new reddit posts: {topics_df.shape[0]} past posts: {topics_old_df.shape[0]} all posts: {topics_all_df.shape[0]}\")\n",
    "        topics_new_df = topics_all_df.drop_duplicates(subset = [\"id\"], keep='last', inplace=False)\n",
    "        print(f\"all reddit posts: {topics_new_df.shape}\")\n",
    "        topics_new_df.to_csv(file_path, index=False)\n",
    "    else:\n",
    "        print(f\"reddit posts: {topics_df.shape}\")\n",
    "        topics_df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661a44bc",
   "metadata": {},
   "source": [
    "## [Option] Update and save dataset\n",
    "We perform the following actions for meargin with old data from pass:\n",
    "\n",
    "* Load old data\n",
    "* Merge the two datasets\n",
    "* Save the merged data\n",
    "We also log here the information on the updated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1c82ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_and_save_dataset(topics_df):   \n",
    "    file_path = \"../input/wallstreetbets-2022/wallstreetbets_2022.csv\"\n",
    "    out_file_path = \"wallstreetbets_2022.csv\"\n",
    "    if run:\n",
    "        run[\"rows_new\"] = topics_df.shape[0]\n",
    "        run[\"cols_new\"] = topics_df.shape[1]\n",
    "    if os.path.exists(file_path):\n",
    "        topics_old_df = pd.read_csv(file_path)\n",
    "        if run:\n",
    "            run[\"rows_old\"] = topics_old_df.shape[0]\n",
    "            run[\"cols_old\"] = topics_old_df.shape[1]\n",
    "        print(f\"past reddit posts: {topics_old_df.shape}\")\n",
    "        topics_all_df = pd.concat([topics_old_df, topics_df], axis=0)\n",
    "        print(f\"new reddit posts: {topics_df.shape[0]} past posts: {topics_old_df.shape[0]} all posts: {topics_all_df.shape[0]}\")\n",
    "        topics_new_df = topics_all_df.drop_duplicates(subset = [\"id\"], keep='last', inplace=False)\n",
    "        print(f\"all reddit posts: {topics_new_df.shape}\")\n",
    "        if run:\n",
    "            run[\"rows_merged\"] = topics_old_df.shape[0]\n",
    "            run[\"cols_merged\"] = topics_old_df.shape[1]\n",
    "        topics_new_df.to_csv(out_file_path, index=False)\n",
    "    else:\n",
    "        print(f\"wallstreetbets posts: {topics_df.shape}\")\n",
    "        topics_df.to_csv(out_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c03601f",
   "metadata": {},
   "source": [
    "## Build connectoin with reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84d16590",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    reddit = reddit_connection()\n",
    "    topics_data_df = build_dataset(reddit)\n",
    "    update_and_save_dataset(topics_data_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
