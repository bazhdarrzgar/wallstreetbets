{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 62221,
     "status": "ok",
     "timestamp": 1618630239506,
     "user": {
      "displayName": "Sispapjen",
      "photoUrl": "",
      "userId": "00407414900530577219"
     },
     "user_tz": 240
    },
    "id": "tSmCrU8CYLkf",
    "outputId": "a602f6bc-6962-45ec-af31-4da2c35f35de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark in /home/soyanswartz/.local/lib/python3.10/site-packages (3.3.1)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in /home/soyanswartz/.local/lib/python3.10/site-packages (from pyspark) (0.10.9.5)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: praw in /home/soyanswartz/.local/lib/python3.10/site-packages (7.1.0)\n",
      "Requirement already satisfied: update-checker>=0.17 in /home/soyanswartz/.local/lib/python3.10/site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in /home/soyanswartz/.local/lib/python3.10/site-packages (from praw) (1.4.1)\n",
      "Requirement already satisfied: prawcore<2.0,>=1.3.0 in /home/soyanswartz/.local/lib/python3.10/site-packages (from praw) (1.5.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in /home/soyanswartz/.local/lib/python3.10/site-packages (from prawcore<2.0,>=1.3.0->praw) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/soyanswartz/.local/lib/python3.10/site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.3.0->praw) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/soyanswartz/.local/lib/python3.10/site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.3.0->praw) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/soyanswartz/.local/lib/python3.10/site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.3.0->praw) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/soyanswartz/.local/lib/python3.10/site-packages (from requests<3.0,>=2.6.0->prawcore<2.0,>=1.3.0->praw) (2022.9.24)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: iexfinance in /home/soyanswartz/.local/lib/python3.10/site-packages (0.5.0)\n",
      "Requirement already satisfied: pandas in /home/soyanswartz/.local/lib/python3.10/site-packages (from iexfinance) (1.5.0)\n",
      "Requirement already satisfied: requests in /home/soyanswartz/.local/lib/python3.10/site-packages (from iexfinance) (2.28.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/soyanswartz/.local/lib/python3.10/site-packages (from pandas->iexfinance) (2022.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/soyanswartz/.local/lib/python3.10/site-packages (from pandas->iexfinance) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/soyanswartz/.local/lib/python3.10/site-packages (from pandas->iexfinance) (1.23.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/soyanswartz/.local/lib/python3.10/site-packages (from requests->iexfinance) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/soyanswartz/.local/lib/python3.10/site-packages (from requests->iexfinance) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/soyanswartz/.local/lib/python3.10/site-packages (from requests->iexfinance) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/soyanswartz/.local/lib/python3.10/site-packages (from requests->iexfinance) (3.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/soyanswartz/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->iexfinance) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pickle-mixin\n",
      "  Downloading pickle-mixin-1.0.2.tar.gz (5.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: pickle-mixin\n",
      "  Building wheel for pickle-mixin (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pickle-mixin: filename=pickle_mixin-1.0.2-py3-none-any.whl size=5991 sha256=0b7ad3344a348e6e774ee3a1ad29703162b7639af83562fb90f1e1799bce0df8\n",
      "  Stored in directory: /home/soyanswartz/.cache/pip/wheels/fc/3c/04/2932798281e4075dc4eadd6c6c79ee66630ee5266ae32731a3\n",
      "Successfully built pickle-mixin\n",
      "Installing collected packages: pickle-mixin\n",
      "Successfully installed pickle-mixin-1.0.2\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/soyanswartz/.local/lib/python3.10/site-packages (1.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/soyanswartz/.local/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/soyanswartz/.local/lib/python3.10/site-packages (from pandas) (2022.2.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/soyanswartz/.local/lib/python3.10/site-packages (from pandas) (1.23.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/soyanswartz/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting requests-futures\n",
      "  Downloading requests_futures-1.0.0-py2.py3-none-any.whl (7.4 kB)\n",
      "Requirement already satisfied: requests>=1.2.0 in /home/soyanswartz/.local/lib/python3.10/site-packages (from requests-futures) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/soyanswartz/.local/lib/python3.10/site-packages (from requests>=1.2.0->requests-futures) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/soyanswartz/.local/lib/python3.10/site-packages (from requests>=1.2.0->requests-futures) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/soyanswartz/.local/lib/python3.10/site-packages (from requests>=1.2.0->requests-futures) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/soyanswartz/.local/lib/python3.10/site-packages (from requests>=1.2.0->requests-futures) (3.4)\n",
      "Installing collected packages: requests-futures\n",
      "Successfully installed requests-futures-1.0.0\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: holidays in /home/soyanswartz/.local/lib/python3.10/site-packages (0.16)\n",
      "Requirement already satisfied: convertdate>=2.3.0 in /home/soyanswartz/.local/lib/python3.10/site-packages (from holidays) (2.4.0)\n",
      "Requirement already satisfied: korean-lunar-calendar in /home/soyanswartz/.local/lib/python3.10/site-packages (from holidays) (0.3.1)\n",
      "Requirement already satisfied: python-dateutil in /home/soyanswartz/.local/lib/python3.10/site-packages (from holidays) (2.8.2)\n",
      "Requirement already satisfied: hijri-converter in /home/soyanswartz/.local/lib/python3.10/site-packages (from holidays) (2.2.4)\n",
      "Requirement already satisfied: pymeeus<=1,>=0.3.13 in /home/soyanswartz/.local/lib/python3.10/site-packages (from convertdate>=2.3.0->holidays) (0.5.11)\n",
      "Requirement already satisfied: six>=1.5 in /home/soyanswartz/.local/lib/python3.10/site-packages (from python-dateutil->holidays) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install praw\n",
    "!pip3 install iexfinance\n",
    "!pip install pickle-mixin\n",
    "!pip install pandas\n",
    "!pip install requests-futures\n",
    "!pip install holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "KV_t_JDlZHAg"
   },
   "outputs": [],
   "source": [
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext as sc\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from iexfinance.stocks import Stock\n",
    "from iexfinance.stocks import get_historical_data\n",
    "import os\n",
    "# tools\n",
    "import re\n",
    "import math\n",
    "import json\n",
    "import requests\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import date\n",
    "from datetime import datetime, timedelta\n",
    "import string\n",
    "import holidays\n",
    "\n",
    "# input true for sandbox\n",
    "def sandbox(change):\n",
    "  if change:\n",
    "    # Set IEX Finance API Token for Sandbox test mode\n",
    "    os.environ['IEX_API_VERSION'] = 'iexcloud-sandbox'\n",
    "    os.environ['IEX_TOKEN'] = 'sk_21c4a511a13e4cbe9260e15c89b0a304'\n",
    "#     os.environ['IEX_TOKEN'] = 'Tsk_4060833567884b49870980c4a917aa92'\n",
    "  else:\n",
    "    # Real\n",
    "    os.environ['IEX_API_VERSION'] = 'stable'\n",
    "    os.environ['IEX_TOKEN'] = ''\n",
    "\n",
    "sandbox(True)\n",
    "\n",
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Spark SQL basic example\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()\n",
    "    return spark\n",
    "spark = init_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wK4nDaIo9KCf"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Function to find the ticker of the stock talked about in a post.\n",
    "'''\n",
    "\n",
    "# helper function for get_ticker, extracts ticker after dollar signs if exists\n",
    "def check_after_dollarsign(body, start_index):\n",
    "   \"\"\"\n",
    "   Given a starting index and text, this will extract the ticker, return None if it is incorrectly formatted.\n",
    "   \"\"\"\n",
    "   count  = 0\n",
    "   ticker = \"\"\n",
    "\n",
    "   for char in body[start_index:]:\n",
    "      # if it should return\n",
    "      if not char.isalpha():\n",
    "         # if there aren't any letters following the $\n",
    "         if (count == 0):\n",
    "            return None\n",
    "\n",
    "         return ticker.upper()\n",
    "      else:\n",
    "         ticker += char\n",
    "         count += 1\n",
    "\n",
    "   return ticker.upper()\n",
    "\n",
    "# function to retrieve ticker from a body of text\n",
    "def get_ticker(body):\n",
    "   # frequent words that look like tickers but aren't\n",
    "   blacklist_words = [\n",
    "      \"YOLO\", \"TOS\", \"CEO\", \"CFO\", \"CTO\", \"DD\", \"BTFD\", \"WSB\", \"OK\", \"RH\",\n",
    "      \"KYS\", \"FD\", \"TYS\", \"US\", \"USA\", \"IT\", \"ATH\", \"RIP\", \"BMW\", \"GDP\",\n",
    "      \"OTM\", \"ATM\", \"ITM\", \"IMO\", \"LOL\", \"DOJ\", \"BE\", \"PR\", \"PC\", \"ICE\",\n",
    "      \"TYS\", \"ISIS\", \"PRAY\", \"PT\", \"FBI\", \"SEC\", \"GOD\", \"NOT\", \"POS\", \"COD\",\n",
    "      \"AYYMD\", \"FOMO\", \"TL;DR\", \"EDIT\", \"STILL\", \"LGMA\", \"WTF\", \"RAW\", \"PM\",\n",
    "      \"LMAO\", \"LMFAO\", \"ROFL\", \"EZ\", \"RED\", \"BEZOS\", \"TICK\", \"IS\", \"DOW\"\n",
    "      \"AM\", \"PM\", \"LPT\", \"GOAT\", \"FL\", \"CA\", \"IL\", \"PDFUA\", \"MACD\", \"HQ\",\n",
    "      \"OP\", \"DJIA\", \"PS\", \"AH\", \"TL\", \"DR\", \"JAN\", \"FEB\", \"JUL\", \"AUG\",\n",
    "      \"SEP\", \"SEPT\", \"OCT\", \"NOV\", \"DEC\", \"FDA\", \"IV\", \"ER\", \"IPO\", \"RISE\"\n",
    "      \"IPA\", \"URL\", \"MILF\", \"BUT\", \"SSN\", \"FIFA\", \"USD\", \"CPU\", \"AT\",\n",
    "      \"GG\", \"ELON\", \"I\", \"WE\", \"A\"\n",
    "   ]\n",
    "\n",
    "   # FIRST CHECK IF THERE'S A $TICKER WITH DOLLAR SIGN\n",
    "   if '$' in body:\n",
    "      index = body.find('$') + 1\n",
    "      word = check_after_dollarsign(body, index)\n",
    "      \n",
    "      if word and word not in blacklist_words:\n",
    "         try:\n",
    "            # special case for $ROPE\n",
    "            if word != \"ROPE\":\n",
    "               # sends request to IEX API to determine whether the current word is a valid ticker\n",
    "               # if it isn't, it'll return an error and therefore continue on to the next word\n",
    "               price = Stock(word).get_company()\n",
    "               return word\n",
    "         except Exception as e:\n",
    "            pass\n",
    "   \n",
    "   # IF NO TICKER WITH DOLLAR SIGN, CHECK FOR TICKER WITHOUT IT: splits every body into list of words\n",
    "   word_list = re.sub(\"[^\\w]\", \" \",  body).split()\n",
    "   for count, word in enumerate(word_list):\n",
    "      # initial screening of words\n",
    "      if word.isupper() and len(word) >= 1 and (word.upper() not in blacklist_words) and len(word) <= 5 and word.isalpha():\n",
    "         try:\n",
    "            # special case for $ROPE\n",
    "            if word != \"ROPE\":\n",
    "               price = Stock(word).get_company()\n",
    "               return word\n",
    "         except Exception as e: \n",
    "            continue\n",
    "      \n",
    "   # if no ticker was found\n",
    "   return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71172,
     "status": "ok",
     "timestamp": 1618630248484,
     "user": {
      "displayName": "Sispapjen",
      "photoUrl": "",
      "userId": "00407414900530577219"
     },
     "user_tz": 240
    },
    "id": "pt_uZ0yx9jm1",
    "outputId": "2b3831cf-462d-4bee-bd95-3ee917f3b9d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting random ticker:  AAPL\n",
      "2021-04-06    130.88\n",
      "Name: close, dtype: object\n",
      "130.88\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Test IEXFinance API ticker extraction\n",
    "'''\n",
    "text = \"I'm going to buy some AAPL yeee.\"\n",
    "ticker = get_ticker(text)\n",
    "# Individual stock test\n",
    "#hi = Stock(\"asdlkjf\").get_company()\n",
    "print(\"Getting random ticker: \", ticker)\n",
    "#quote = Stock(\"AAPL\")\n",
    "# get's stock price\n",
    "#one_price = quote.get_quote().latestPrice[ticker]\n",
    "#print(\"one price: \", one_price)\n",
    "now = datetime.now().timestamp()\n",
    "end = datetime.fromtimestamp(1617658992)\n",
    "start = datetime.fromtimestamp(1617658992 - 86400)\n",
    "# gets the closing prices from a week ago till today. use the latest price!\n",
    "price = get_historical_data(\"AAPL\", start, end, close_only=True)\n",
    "print(price.close)\n",
    "# # get last price!\n",
    "print(price.close[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hQ1VC_zARJ62"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "- return false if date is holiday or weekend (market close), else return date\n",
    "'''\n",
    "def get_start_date(created):\n",
    "  # 1 day before post date\n",
    "  us_holidays = holidays.UnitedStates(years = 2021)\n",
    "  ticker_date = datetime.fromtimestamp(int(created) - 86400).date()\n",
    "  \n",
    "  # if not holiday or good friday or weekend\n",
    "  if ticker_date in us_holidays or ticker_date == datetime(2021, 4, 2).date():\n",
    "    return False\n",
    "  if ticker_date.weekday() in [5,6]:\n",
    "    return False\n",
    "  \n",
    "  return ticker_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71155,
     "status": "ok",
     "timestamp": 1618630248487,
     "user": {
      "displayName": "Sispapjen",
      "photoUrl": "",
      "userId": "00407414900530577219"
     },
     "user_tz": 240
    },
    "id": "8mY1Y3M8ZE3S",
    "outputId": "34a02551-04f7-4ae0-9055-e8bb90bbc0b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "newyear = 1609609392\n",
    "get_start_date(newyear)\n",
    "\n",
    "ticker_date = datetime.fromtimestamp(int(1617658992)- 86400 - 86400 - 86400).date()\n",
    "print(ticker_date == datetime(2021, 4, 2).date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "olDQK62m1WE9"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Compute growth % of associated stock in a given post.\n",
    "'''\n",
    "# computes growth % of given DD\n",
    "# (today's price <> price at DD's date) = percentage growth from then to now of the stock\n",
    "def growth1(ticker, created):\n",
    "    if not ticker or ticker == \"None\":\n",
    "        return \"N/A\"\n",
    "    # get today's date and DD's date (ranges from <>1 week in case of weekends/holidays)\n",
    "    try:\n",
    "        # get today's price\n",
    "        price_today = Stock(ticker).get_quote().latestPrice[ticker]\n",
    "\n",
    "        ticker_date_start = get_start_date(created)\n",
    "        ticker_date_end = datetime.fromtimestamp(int(created))\n",
    "\n",
    "        # dates for post creation: loop until get valid date\n",
    "        counter = 0\n",
    "        new_date = created\n",
    "        while not ticker_date_start and counter < 20:\n",
    "          counter += 1\n",
    "          new_date -= 86400\n",
    "          ticker_date_start = get_start_date(new_date)\n",
    "        # get DD date's price\n",
    "        if ticker_date_start:\n",
    "          ticker_date_end = ticker_date_start + timedelta(days=0.8)\n",
    "          price_ticker_date = get_historical_data(ticker, ticker_date_start, ticker_date_end, close_only=True).close[0]\n",
    "\n",
    "        # compute percentage growth\n",
    "        percentage = ((price_today / price_ticker_date) - 1) * 100\n",
    "        return \"{:.2f}\".format(percentage) + \"%\"\n",
    "    except Exception as e:\n",
    "        return \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Msq6kRNLLnk0"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Compute growth % of associated stock in a given post.\n",
    "'''\n",
    "# computes growth % of given DD\n",
    "# (today's price <> price at DD's date) = percentage growth from then to now of the stock\n",
    "def growth(ticker, created):\n",
    "    if not ticker or ticker == \"None\":\n",
    "        return \"N/A\"\n",
    "    # get today's date and DD's date (ranges from <>1 week in case of weekends/holidays)\n",
    "    try:\n",
    "        # get today's price\n",
    "        price_today = Stock(ticker).get_quote().latestPrice[ticker]\n",
    "        print(\"ok\",price_today)\n",
    "\n",
    "        ticker_date_start = get_start_date(created)\n",
    "        ticker_date_end = datetime.fromtimestamp(int(created))\n",
    "\n",
    "        # dates for post creation: loop until get valid date\n",
    "        counter = 0\n",
    "        new_date = created\n",
    "        while not ticker_date_start and counter < 20:\n",
    "          counter += 1\n",
    "          new_date -= 86400\n",
    "          ticker_date_start = get_start_date(new_date)\n",
    "        # get DD date's price\n",
    "        if ticker_date_start:\n",
    "          # sandbox(True)\n",
    "          # test = get_historical_data(ticker, ticker_date_start, ticker_date_end, close_only=True).close[0]\n",
    "          # sandbox(False)\n",
    "          ticker_date_end = ticker_date_start + timedelta(days=0.8)\n",
    "          test = get_historical_data(ticker, ticker_date_start, ticker_date_end, close_only=True)\n",
    "          print(\"test\", test)\n",
    "          price_ticker_date = test.close[0]\n",
    "\n",
    "        print(ticker_date_start, ticker_date_end)\n",
    "        # compute percentage growth\n",
    "        percentage = ((price_today / price_ticker_date) - 1) * 100\n",
    "        return \"{:.2f}\".format(percentage) + \"%\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "executionInfo": {
     "elapsed": 71943,
     "status": "ok",
     "timestamp": 1618630249299,
     "user": {
      "displayName": "Sispapjen",
      "photoUrl": "",
      "userId": "00407414900530577219"
     },
     "user_tz": 240
    },
    "id": "SQlBbmteP7o7",
    "outputId": "8a0d2153-3fa1-420b-e8d5-76d747e3022f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-06 00:07:16 2021-04-07 00:07:16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-04-07</th>\n",
       "      <td>46.4113</td>\n",
       "      <td>19684407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              close    volume\n",
       "2021-04-07  46.4113  19684407"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Test growth function\n",
    "'''\n",
    "# 1/11/2021 -> dont work\n",
    "#date = 1610473392\n",
    "date = 1617656836\n",
    "ticker = \"GME\"\n",
    "ticker_date_start = datetime.fromtimestamp(int(date))\n",
    "ticker_date_end = ticker_date_start + timedelta(days=1)\n",
    "print(ticker_date_start, ticker_date_end)\n",
    "get_historical_data(ticker, ticker_date_start, ticker_date_end, close_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zBk3suhmCqFA"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Data cleaning step\n",
    "- Remove all punctuation, numbers, new lines, tabs, consecutive spaces in text.\n",
    "'''\n",
    "def clean_text(text):\n",
    "  # remove punctuation except $\n",
    "  cleaned = text.translate(str.maketrans(' ', ' ', string.punctuation.replace('$','') + '’')).lower()\n",
    "  # remove links (http)\n",
    "  cleaned = re.sub(\"http\\w+\", \" \", cleaned)\n",
    "  # remove digits\n",
    "  cleaned = cleaned.translate({ord(k): None for k in string.digits})\n",
    "  # remove tabs/newlines\n",
    "  cleaned = cleaned.replace(\"\\n\", \" \").replace(\"\\t\", \" \").strip()\n",
    "  # remove double space\n",
    "  cleaned = re.sub(' +', ' ', cleaned)\n",
    "  return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 120
    },
    "executionInfo": {
     "elapsed": 71916,
     "status": "ok",
     "timestamp": 1618630249304,
     "user": {
      "displayName": "Sispapjen",
      "photoUrl": "",
      "userId": "00407414900530577219"
     },
     "user_tz": 240
    },
    "id": "jDq9c0B9Cy0C",
    "outputId": "4c4e2b0f-66c5-4763-d5ee-f545966f9fba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hi I'm Pan. We a213re http://kek.com g5.3oin2g 5.4 to 3 havhttp://kek.come a VERY\n",
      "  [GOOD GRADE] in \tthis class: \n",
      "not even  # kidding, @our project is 2 good... Soyeah!!! If you ask me 'how?' i'll tell u we got 100%.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hi im pan we are going to hav a very good grade in this class not even kidding our project is good soyeah if you ask me how ill tell u we got'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Testing clean_text()\n",
    "'''\n",
    "dirty = \" Hi I'm Pan. We a213re http://kek.com g5.3oin2g 5.4 to 3 havhttp://kek.come a VERY\\n  [GOOD GRADE] in \\tthis class: \\nnot even  # kidding, @our project is 2 good... Soyeah!!! If you ask me 'how?' i'll tell u we got 100%.\"\n",
    "print(dirty)\n",
    "print()\n",
    "clean_text(dirty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "k554ETe-Iwf5"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Data Filtering: validate post before adding.\n",
    "'''\n",
    "\n",
    "def validate_post(post):\n",
    "  return (post['link_flair_text']\n",
    "    and post['upvote_ratio'] > 0.5\n",
    "    and post['link_flair_css_class']\n",
    "    and post['selftext']\n",
    "    and not post['selftext'].isspace()\n",
    "    and post['selftext'] != \"removed\"\n",
    "    and post['selftext'] != \"[deleted]\"\n",
    "    and post['score'] >= 5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZrOYRS9T3hNS"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Wrapper of requests\n",
    "- uri: uri that we are making request from\n",
    "- max_retry: maximum number of trial before timeout\n",
    "\"\"\"\n",
    "sesh = requests.session()\n",
    "def get_request(uri, max_retry = 5):\n",
    "  def get(uri):\n",
    "    global get_attempts\n",
    "    global sesh\n",
    "    get_attempts += 1\n",
    "    response = sesh.get(uri, timeout=20)\n",
    "    assert response.status_code == 200\n",
    "    return json.loads(response.content)\n",
    "  # Retry if request call failed\n",
    "  retry = 1\n",
    "  while retry < max_retry:\n",
    "    try:\n",
    "      response = get(uri)\n",
    "      return response\n",
    "    except Exception as e:\n",
    "      if 'timed out' in str(e):\n",
    "        print(\"Retry \" + str(retry)+ \" Timed out. Request #\" + str(get_attempts))\n",
    "      retry += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FQkcQb6TnlR_"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Gets the all the posts from a given subreddit in the specific time range.\n",
    "- subreddit: name of subreddit\n",
    "- begin: timestamp (in unix) of start date\n",
    "- end: timestamp (in unix) of end date\n",
    "- returns: list of all the posts in the time interval as objects. {id=\"..\", title=\"...\", etc...}\n",
    "\"\"\"\n",
    "def get_posts(subreddit, begin, end):\n",
    "  # Max size of each Pushshift API request is 100 posts.\n",
    "  SIZE = 100\n",
    "  #'https://api.pushshift.io/reddit/search/submission?subreddit=wallstreetbets&score=>5&size=25&selftext:not=\"preview.redd.it\"&fields=id,created_utc,title,score,upvote_ratio,author,link_flair_text,link_flair_css_class,num_comments,selftext,url'\n",
    "  PUSHSHIFT_URI = r'https://api.pushshift.io/reddit/search/submission?subreddit={}&after={}&before={}&size={}&is_video=false&fields=total_awards_received,id,created_utc,title,score,upvote_ratio,author,link_flair_text,link_flair_css_class,num_comments,selftext,url'\n",
    "  nb_requests_made = 1\n",
    "  # filter the posts data\n",
    "  def filter_posts(uri, begin, end):\n",
    "    full_posts = get_request(uri.format(subreddit, begin, end, SIZE))\n",
    "    if full_posts is None:\n",
    "      raise ValueError(\"Response is empty or none.\")\n",
    "    posts = []\n",
    "    if full_posts!=None:\n",
    "      for post in full_posts['data']:\n",
    "        try:\n",
    "          if validate_post(post):\n",
    "            sandbox(True)\n",
    "            ticker =  get_ticker(post['title'])\n",
    "            posts.append({\\\n",
    "              'id': post['id'],\\\n",
    "              'ticker': ticker, \\\n",
    "              'growth': growth(ticker, post['created_utc']),\\\n",
    "              'title': clean_text(post['title']),\\\n",
    "              'score': post['score'],\\\n",
    "              'upvote_ratio': post['upvote_ratio'],\\\n",
    "              'author': post['author'],\\\n",
    "              'created_utc': post['created_utc'],\\\n",
    "              'flair': post['link_flair_text'],\\\n",
    "              'flaircss': post['link_flair_css_class'],\\\n",
    "              'num_comments': post['num_comments'],\\\n",
    "              'text': clean_text(post['selftext']),\\\n",
    "              'total_awards': post['total_awards_received'],\\\n",
    "              'url': post['url']\\\n",
    "            })\n",
    "        except:\n",
    "          pass\n",
    "      # get timestamp of last post\n",
    "      #print(full_posts['data'][0][\"score\"])\n",
    "      last_timestamp = full_posts['data'][-1]['created_utc']\n",
    "      posts_amount = len(full_posts['data'])\n",
    "          \n",
    "      #return list(filtered)\n",
    "      return [posts, last_timestamp, posts_amount]\n",
    "    else:\n",
    "      return None \n",
    "  posts_etc = filter_posts(PUSHSHIFT_URI, begin, end)\n",
    "  posts = posts_etc[0]\n",
    "  last_timestamp = posts_etc[1]\n",
    "  posts_amount = posts_etc[2]\n",
    "\n",
    "  # If reached limit of 100 posts retrieved, make request again until 'end' time.\n",
    "  while posts_amount == SIZE:\n",
    "    \n",
    "    # Timestamp of the last post we previously retrieved\n",
    "    new_begin = last_timestamp - 10\n",
    "    more_posts_etc = filter_posts(PUSHSHIFT_URI, new_begin, end)\n",
    "    if more_posts_etc==None:\n",
    "      time.sleep(1)\n",
    "      last_timestamp+=10\n",
    "      print(\"sleep\")\n",
    "    else:\n",
    "      last_timestamp = more_posts_etc[1]\n",
    "      posts_amount = more_posts_etc[2]\n",
    "      posts.extend(more_posts_etc[0])\n",
    "      nb_requests_made += 1\n",
    "      print(new_begin,end)\n",
    "    \n",
    "  print(\"Number of requests made: \", nb_requests_made)\n",
    "  return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71903,
     "status": "ok",
     "timestamp": 1618630249315,
     "user": {
      "displayName": "Sispapjen",
      "photoUrl": "",
      "userId": "00407414900530577219"
     },
     "user_tz": 240
    },
    "id": "pv07kukZgPq5",
    "outputId": "cc186ce6-4dfb-43f9-8737-dc4ca3f51eec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 10, 20, 12, 32, 53)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.fromtimestamp(1666949573) - timedelta(days=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 95418,
     "status": "ok",
     "timestamp": 1618630831223,
     "user": {
      "displayName": "Sispapjen",
      "photoUrl": "",
      "userId": "00407414900530577219"
     },
     "user_tz": 240
    },
    "id": "HPfvW-hwvTFh",
    "outputId": "b4407b62-e516-440e-e594-6c54d6151a25"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Retrieve posts\n",
    "- nb_days_from_today: number of days from 4 days ago you want to retrieve\n",
    "- return: lists of all posts in time interval\n",
    "\"\"\"\n",
    "get_attempts = 0\n",
    "def retrieve(nb_days_from_today):\n",
    "  global get_attempts\n",
    "  end = math.ceil(datetime.utcnow().timestamp() - 345600)\n",
    "  if nb_days_from_today < 3650:\n",
    "    begin = math.ceil((datetime.fromtimestamp(end) - timedelta(days=nb_days_from_today)).timestamp())\n",
    "  else:\n",
    "    begin = nb_days_from_today\n",
    "  print(\"Timestamps: \", begin, end)\n",
    "  posts = get_posts('wallstreetbets', begin, end)\n",
    "\n",
    "  unique_posts = np.unique([post['id'] for post in posts])\n",
    "  print(\"Size: \", len(posts))\n",
    "  print(\"Size of uniques: \", len(unique_posts))\n",
    "  print(\"Example posts: \", posts[:5])\n",
    "  print(\"Total requests: \" + str(get_attempts))\n",
    "  return posts\n",
    "\n",
    "posts = retrieve(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "tvbLzAGHuHoT"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Output to CSV\n",
    "\n",
    "using RDD and DF\n",
    "\"\"\"\n",
    "# convert unix timestamp to date e.g.: '2021-04-04'\n",
    "def convert_to_date(timestamp):\n",
    "  return str(datetime.fromtimestamp(int(timestamp)).date())\n",
    "\n",
    "posts_rdd = spark.sparkContext.parallelize(posts)\n",
    "posts_rdd = posts_rdd.map(lambda post: Row(id=post['id'], ticker=post['ticker'], growth=post['growth'], title=post['title'], flair=str(post['flair']), score=post['score'], upvote_ratio=post['upvote_ratio'], author=str(post['author']), num_comments=post['num_comments'], text=post['text'].lower(), created=convert_to_date(post['created_utc']), url=post['url']))\n",
    "# eliminate duplicates\n",
    "posts_rdd = posts_rdd.distinct()\n",
    "# serialize rdd, maybe better as pandas\n",
    "#posts_rdd.saveAsPickleFile(\"pickled_WSBposts_rdd-test\")\n",
    "\n",
    "# convert to DF\n",
    "posts_df = spark.createDataFrame(posts_rdd)\n",
    "print(posts_df.count())\n",
    "panda_posts = posts_df.toPandas()\n",
    "\n",
    "# write to csv\n",
    "posts_df.coalesce(1).write.csv('all_posts.csv', header=True)\n",
    "panda_posts"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "WallStreetBets-Preprocessing.ipynb",
   "provenance": [
    {
     "file_id": "108ofFsEzbswK2E1tzkPfr6UU6jPHRTx-",
     "timestamp": 1616988199266
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
